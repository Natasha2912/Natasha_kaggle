{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb61f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Natasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Natasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Natasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7cd739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d0dcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4c681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f6b5f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(52)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfffe222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da226ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e8c956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7561, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dc9ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(text):\n",
    "    text = re.sub(r'(http.*)|#', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stops = stopwords.words('english')\n",
    "    clean_tokens = [token.lower() for token in tokens if token.lower() not in stops and token.isalnum()]\n",
    "    return ' '.join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af51b84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Natasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked place notified officers evacua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target\n",
       "0     NaN      NaN       deeds reason earthquake may allah forgive us       1\n",
       "1     NaN      NaN              forest fire near la ronge sask canada       1\n",
       "2     NaN      NaN  residents asked place notified officers evacua...       1\n",
       "3     NaN      NaN  people receive wildfires evacuation orders cal...       1\n",
       "4     NaN      NaN  got sent photo ruby alaska smoke wildfires pou...       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "df['text'] = df['text'].map(clean_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27146d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword      0.806772\n",
       "location    33.064409\n",
       "text         0.000000\n",
       "target       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83c3d233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(7500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keyword'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "687176ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in d:\\practice flask\\.venv\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (2.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: jinja2 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (2.10.4)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: setuptools in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (57.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in d:\\practice flask\\.venv\\lib\\site-packages (from spacy) (8.3.3)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\practice flask\\.venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\practice flask\\.venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\practice flask\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\practice flask\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\practice flask\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\practice flask\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\practice flask\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\practice flask\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\practice flask\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: blis<1.2.0,>=1.1.0 in d:\\practice flask\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\practice flask\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in d:\\practice flask\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\practice flask\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\practice flask\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\practice flask\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\practice flask\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\practice flask\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\practice flask\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\practice flask\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\practice flask\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: wrapt in d:\\practice flask\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\practice flask\\.venv\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'D:\\Practice flask\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'd:\\Practice flask\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquake may allah forgive we</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resident ask place notify officer evacuation s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>get send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target\n",
       "0     NaN      NaN        deed reason earthquake may allah forgive we       1\n",
       "1     NaN      NaN              forest fire near la ronge sask canada       1\n",
       "2     NaN      NaN  resident ask place notify officer evacuation s...       1\n",
       "3     NaN      NaN  people receive wildfire evacuation order calif...       1\n",
       "4     NaN      NaN  get send photo ruby alaska smoke wildfire pour...       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatizing using spacy\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "    return lemmatized_text\n",
    "\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4ce795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Natasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Natasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Natasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquake may allah forgive we</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evacuation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resident ask place notify officer evacuation s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wildfire evacuation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wildfire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>get send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword location  \\\n",
       "0           earthquake      NaN   \n",
       "1                 fire      NaN   \n",
       "2           evacuation      NaN   \n",
       "3  wildfire evacuation      NaN   \n",
       "4             wildfire      NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0        deed reason earthquake may allah forgive we       1  \n",
       "1              forest fire near la ronge sask canada       1  \n",
       "2  resident ask place notify officer evacuation s...       1  \n",
       "3  people receive wildfire evacuation order calif...       1  \n",
       "4  get send photo ruby alaska smoke wildfire pour...       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Predefined list of disaster-related keywords\n",
    "disaster_keywords = {\"earthquake\", \"fire\", \"flood\", \"hurricane\", \"storm\", \"evacuation\",\n",
    "                     \"tornado\", \"tsunami\", \"disaster\", \"wildfire\", \"explosion\", \"drought\",\n",
    "                     \"landslide\", \"eruption\", \"pandemic\", \"emergency\", \"crisis\", \"sismo\", \"typhoon\"}\n",
    "\n",
    "# Function to extract disaster-related keyword and proper nouns from text\n",
    "def extract_keywords(text):\n",
    "    # Handle NaN values in 'text' by converting to string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    # Tokenize the text and apply POS tagging\n",
    "    words = word_tokenize(text.lower())  # Convert to lowercase for case-insensitive matching\n",
    "    tagged_words = pos_tag(words)  # POS tagging\n",
    "\n",
    "    # Extract disaster-related keywords\n",
    "    disaster_matches = [word for word in words if word in disaster_keywords]\n",
    "\n",
    "    # Extract proper nouns (NNP and NNPS)\n",
    "    proper_nouns = [word for word, tag in tagged_words if tag in ['NNP', 'NNPS']]\n",
    "\n",
    "    # Combine disaster-related keywords and proper nouns\n",
    "    if disaster_matches:\n",
    "        return ' '.join(disaster_matches)  # Return disaster-related keyword if found\n",
    "    elif proper_nouns:\n",
    "        return ' '.join(proper_nouns)  # Return proper nouns if no disaster keywords are found\n",
    "    return None  # Return None if no keyword found\n",
    "\n",
    "# Apply the keyword extraction only on rows where 'keyword' is NaN\n",
    "df['keyword'] = df.apply(\n",
    "    lambda row: extract_keywords(row['text']) if pd.isna(row['keyword']) else row['keyword'], axis=1\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "843ae904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword       36\n",
       "location    2500\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b99a40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(253)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd60decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates based on specific columns\n",
    "duplicate_rows = df[df.duplicated(subset=['text', 'keyword'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6d2efa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1d802d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7308, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c5d11bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquake may allah forgive we</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evacuation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resident ask place notify officer evacuation s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wildfire evacuation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wildfire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>get send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword location  \\\n",
       "0           earthquake      NaN   \n",
       "1                 fire      NaN   \n",
       "2           evacuation      NaN   \n",
       "3  wildfire evacuation      NaN   \n",
       "4             wildfire      NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0        deed reason earthquake may allah forgive we       1  \n",
       "1              forest fire near la ronge sask canada       1  \n",
       "2  resident ask place notify officer evacuation s...       1  \n",
       "3  people receive wildfire evacuation order calif...       1  \n",
       "4  get send photo ruby alaska smoke wildfire pour...       1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d91369bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     keyword location                                               text  \\\n",
      "10      None      NaN                     three people die heat wave far   \n",
      "14      None      NaN      damage school bus 80 multi car crash breaking   \n",
      "15      None      NaN                                                man   \n",
      "16      None      NaN                                         love fruit   \n",
      "17      None      NaN                                      summer lovely   \n",
      "18      None      NaN                                           car fast   \n",
      "19      None      NaN                                    goooooooaaaaaal   \n",
      "20      None      NaN                                         ridiculous   \n",
      "21      None      NaN                                        london cool   \n",
      "22      None      NaN                                        love skiing   \n",
      "23      None      NaN                                      wonderful day   \n",
      "24      None      NaN                                           looooool   \n",
      "25      None      NaN                                   way can eat shit   \n",
      "26      None      NaN                                      nyc last week   \n",
      "27      None      NaN                                    love girlfriend   \n",
      "28      None      NaN                                             cooool   \n",
      "29      None      NaN                                         like pasta   \n",
      "30      None      NaN                                                end   \n",
      "7583    None      NaN  pic 16yr old pkk suicide bomber detonate bomb ...   \n",
      "7584    None      NaN  boxes ready explode explode kitten finally arr...   \n",
      "7587    None      NaN                                   siren everywhere   \n",
      "7588    None      NaN  break isis claim responsibility mosque attack ...   \n",
      "7591    None      NaN  heat wave warn aa ayyo dei plan visit friend year   \n",
      "7592    None      NaN  group suicide bomber detonate vest mosque insi...   \n",
      "7593    None      NaN        hear really loud bang everyone asleep great   \n",
      "7594    None      NaN  gas thing explode hear scream whole street sme...   \n",
      "7596    None      NaN  rt livingsafely nws issue severe thunderstorm ...   \n",
      "7597    None      NaN  mh370 aircraft debris find la reunion miss mal...   \n",
      "7598    None      NaN  lose control car overtake collide bathandnorth...   \n",
      "7601    None      NaN  break la refugio oil spill may costlier bigger...   \n",
      "7603    None      NaN  official say quarantine place alabama home pos...   \n",
      "7605    None      NaN  flip side walmart bomb everyone evacuate stay ...   \n",
      "7606    None      NaN  suicide bomber kill 15 saudi security site mos...   \n",
      "7608    None      NaN   two giant crane hold bridge collapse nearby home   \n",
      "7610    None      NaN                            utc 5 km volcano hawaii   \n",
      "7611    None      NaN  police investigate collided car little portuga...   \n",
      "\n",
      "      target  \n",
      "10         1  \n",
      "14         1  \n",
      "15         0  \n",
      "16         0  \n",
      "17         0  \n",
      "18         0  \n",
      "19         0  \n",
      "20         0  \n",
      "21         0  \n",
      "22         0  \n",
      "23         0  \n",
      "24         0  \n",
      "25         0  \n",
      "26         0  \n",
      "27         0  \n",
      "28         0  \n",
      "29         0  \n",
      "30         0  \n",
      "7583       1  \n",
      "7584       0  \n",
      "7587       0  \n",
      "7588       1  \n",
      "7591       1  \n",
      "7592       1  \n",
      "7593       0  \n",
      "7594       1  \n",
      "7596       1  \n",
      "7597       1  \n",
      "7598       1  \n",
      "7601       1  \n",
      "7603       1  \n",
      "7605       1  \n",
      "7606       1  \n",
      "7608       1  \n",
      "7610       1  \n",
      "7611       1  \n"
     ]
    }
   ],
   "source": [
    "nan_keyword_rows = df[df['keyword'].isna()]\n",
    "\n",
    "# Display the filtered rows\n",
    "print(nan_keyword_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1326ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keyword'] = df['keyword'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d7953a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword        0\n",
       "location    2345\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db664448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('location',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afb115d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>deed reason earthquake may allah forgive we</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fire</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evacuation</td>\n",
       "      <td>resident ask place notify officer evacuation s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wildfire evacuation</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wildfire</td>\n",
       "      <td>get send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword                                               text  \\\n",
       "0           earthquake        deed reason earthquake may allah forgive we   \n",
       "1                 fire              forest fire near la ronge sask canada   \n",
       "2           evacuation  resident ask place notify officer evacuation s...   \n",
       "3  wildfire evacuation  people receive wildfire evacuation order calif...   \n",
       "4             wildfire  get send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d29f54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:real disaster\n",
    "# 0:not real disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "358e6a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword    0\n",
       "text       0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e309ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No null values found in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5de2f3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4228\n",
       "1    3080\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.pie(df['target'].value_counts(), labels=['not real disaster','real disaster'], autopct='%0.1f')\n",
    "plt.title('Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0da772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keyword analysis\n",
    "#Unique Keywords\n",
    "df['keyword'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66124479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most Frequent Keywords\n",
    "df['keyword'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67df8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "df['keyword'].value_counts().head(20).plot(kind='bar')\n",
    "plt.title('Top 10 Keywords')\n",
    "plt.xlabel('Keywords')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea0278",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_keywords = df[df['target'] == 1]['keyword'].value_counts().head(10)\n",
    "print(disaster_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6820356",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_disaster_keywords = df[df['target'] == 0]['keyword'].value_counts().head(10)\n",
    "print(non_disaster_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57615c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of words in each tweet\n",
    "#df['Number_of_words'] = df['text'].apply(lambda x:len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fafc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of sentences in each tweet\n",
    "#df['Number_of_sent'] = df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccdc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866431b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,4))\n",
    "# sns.histplot(df['Number_of_words'], kde=True)\n",
    "# plt.title('Distribution of Text Length')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b80419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "#1.checking percentage of each both target values\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Prepare data for Word2Vec (list of tokenized words per document)\n",
    "tokenized_texts = df['text'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Check the vocabulary size\n",
    "print(f\"Vocabulary size: {len(w2v_model.wv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vector(words, model):\n",
    "    vector = np.zeros(model.vector_size)\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            count += 1\n",
    "    return vector / count if count > 0 else vector\n",
    "\n",
    "# Create feature matrix\n",
    "df['w2v_features'] = tokenized_texts.apply(lambda x: get_document_vector(x,w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f4842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(df['w2v_features'].values)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6827aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000)  # Increased max_iter for convergence\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585cf63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c6f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
